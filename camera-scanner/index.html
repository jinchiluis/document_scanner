<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <title>Document Scanner Demo</title>
  <style>
    body { font-family: system-ui, sans-serif; background: #f5f5f5; margin: 0; padding: 24px; text-align: center; }
    #camera-container { position: relative; display: inline-block; background: #111; border-radius: 12px; }
    video, canvas { max-width: 90vw; border-radius: 12px; }
    #overlay { position: absolute; top: 0; left: 0; pointer-events: none; }
    #controls { margin: 16px 0; }
    button { font-size: 1rem; padding: 12px 28px; border-radius: 7px; border: none; background: #007bff; color: #fff; cursor: pointer; }
    button:disabled { background: #aaa; }
    .status { margin: 18px auto; padding: 12px; border-radius: 8px; max-width: 320px; }
    .status.success { background: #e8ffe8; color: #228c22; }
    .status.error { background: #ffeaea; color: #d60000; }
    .slider-group { margin: 14px 0; }
    .slider-group label { font-size: 0.95em; margin-right: 12px; }
    #preview { margin: 28px auto; max-width: 320px; display: none; }
    #preview img { width: 100%; border-radius: 8px; border: 2px solid #333; }
    #detection-label { position: absolute; top: 10px; left: 10px; padding: 5px 14px; border-radius: 5px; background: rgba(0,0,0,0.7); color: #fff; font-size: 1em;}
    #detection-label.detected { background: rgba(33,200,70,0.88); }
  </style>
</head>
<body>
  <h1>ðŸ“„ Document Scanner Demo</h1>
  <div id="camera-container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
    <div id="detection-label">Searchingâ€¦</div>
  </div>
  <div id="controls">
    <button id="capture-btn" disabled>Initializingâ€¦</button>
    <button id="toggle-btn">Auto Detect: ON</button>
  </div>
  <div class="slider-group">
    <label>Edge Sensitivity <span id="edge-value">50</span></label>
    <input type="range" id="edge-slider" min="10" max="100" value="50" />
    <label>Min Area <span id="area-value">20</span>%</label>
    <input type="range" id="area-slider" min="5" max="50" value="20" />
  </div>
  <div id="status" class="status"></div>
  <div id="preview">
    <h3>ðŸ“‘ Scanned Document:</h3>
    <img id="preview-img" src="" />
  </div>
  <canvas id="hidden-canvas" style="display:none;"></canvas>
  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script>
    // === Globals ===
    let video = document.getElementById('video');
    let overlay = document.getElementById('overlay');
    let overlayCtx = overlay.getContext('2d');
    let hiddenCanvas = document.getElementById('hidden-canvas');
    let hiddenCtx = hiddenCanvas.getContext('2d');
    let autoDetect = true;
    let lastCorners = null;
    let lastDetection = 0;
    let isProcessing = false;
    let edgeThreshold = 50;
    let minAreaPct = 20;

    // === UI Hooks ===
    let captureBtn = document.getElementById('capture-btn');
    let toggleBtn = document.getElementById('toggle-btn');
    let edgeSlider = document.getElementById('edge-slider');
    let areaSlider = document.getElementById('area-slider');
    let statusBox = document.getElementById('status');
    let detectionLabel = document.getElementById('detection-label');
    let preview = document.getElementById('preview');
    let previewImg = document.getElementById('preview-img');

    edgeSlider.oninput = e => {
      edgeThreshold = +e.target.value;
      document.getElementById('edge-value').textContent = edgeThreshold;
    };
    areaSlider.oninput = e => {
      minAreaPct = +e.target.value;
      document.getElementById('area-value').textContent = minAreaPct;
    };

    toggleBtn.onclick = () => {
      autoDetect = !autoDetect;
      toggleBtn.textContent = 'Auto Detect: ' + (autoDetect ? 'ON' : 'OFF');
      if (autoDetect) requestAnimationFrame(detectFrame);
    };

    captureBtn.onclick = () => captureDocument();

    // === Camera setup ===
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment', width: {ideal: 1280}, height: {ideal: 720} }
        });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          setCanvasSize();
          captureBtn.disabled = false;
          captureBtn.textContent = 'ðŸ“¸ Capture';
          showStatus('Camera ready!','success');
          if (autoDetect) requestAnimationFrame(detectFrame);
        };
      } catch (err) {
        showStatus('Camera error: ' + err.message, 'error');
        captureBtn.textContent = 'Camera Failed';
      }
    }
    function setCanvasSize() {
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;
      hiddenCanvas.width = video.videoWidth;
      hiddenCanvas.height = video.videoHeight;
    }

    // === Document Detection Loop ===
    function detectFrame() {
      if (!autoDetect || isProcessing || video.readyState !== 4) {
        requestAnimationFrame(detectFrame);
        return;
      }
      // Get video frame to canvas
      hiddenCtx.drawImage(video, 0, 0, hiddenCanvas.width, hiddenCanvas.height);
      let frame = hiddenCtx.getImageData(0,0,hiddenCanvas.width,hiddenCanvas.height);
      let src = cv.matFromImageData(frame);
      let gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      let blur = new cv.Mat();
      cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);
      let edges = new cv.Mat();
      cv.Canny(blur, edges, edgeThreshold, edgeThreshold*2);

      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      //Jinch manuell
      console.log('Contours found:', contours.size());
      //Jinch manuell

      // Find largest quadrilateral
      let best = null, maxArea = 0;
      for (let i=0; i<contours.size(); ++i) {
        let cnt = contours.get(i);
        let peri = cv.arcLength(cnt, true);
        let approx = new cv.Mat();
        cv.approxPolyDP(cnt, approx, 0.02*peri, true);
        if (approx.rows === 4) {
          let area = cv.contourArea(cnt);
          if (area > maxArea && area > hiddenCanvas.width * hiddenCanvas.height * minAreaPct/100) {
            maxArea = area;
            if (best) best.delete();
            best = approx.clone();
          }
        }
        approx.delete();
        cnt.delete();
      }
      // Draw overlay
      overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
      const now = Date.now();
      if (best) {
        // Extract corners
        let pts = [];
        for (let i=0; i<4; ++i) {
          let p = best.intPtr(i,0);
          pts.push([p[0],p[1]]);
        }
        lastCorners = orderCorners(pts);
        lastDetection = now;
        best.delete();
      }
      // Draw if recent detection
      if (lastCorners && (now-lastDetection < 700)) {
        drawPolygon(lastCorners, "#2ef516");
        detectionLabel.textContent = 'Document Detected!';
        detectionLabel.classList.add('detected');
      } else {
        detectionLabel.textContent = 'Searchingâ€¦';
        detectionLabel.classList.remove('detected');
        lastCorners = null;
      }
      src.delete(); gray.delete(); blur.delete(); edges.delete(); contours.delete(); hierarchy.delete();
      requestAnimationFrame(detectFrame);
    }
    // Draw detected polygon/corners
    function drawPolygon(corners, color) {
      overlayCtx.strokeStyle = color;
      overlayCtx.lineWidth = 4;
      overlayCtx.beginPath();
      overlayCtx.moveTo(corners[0][0], corners[0][1]);
      for (let i=1;i<4;++i) overlayCtx.lineTo(corners[i][0], corners[i][1]);
      overlayCtx.closePath();
      overlayCtx.stroke();
      for (let c of corners) {
        overlayCtx.beginPath();
        overlayCtx.arc(c[0],c[1],8,0,2*Math.PI);
        overlayCtx.fillStyle = color;
        overlayCtx.fill();
      }
    }
    // Robust corner order: tl, tr, br, bl
    function orderCorners(pts) {
      pts = pts.slice().sort((a,b) => a[1]-b[1]);
      let [t1,t2, b1,b2] = pts;
      let [tl, tr] = [t1, t2].sort((a,b) => a[0]-b[0]);
      let [bl, br] = [b1, b2].sort((a,b) => a[0]-b[0]);
      return [tl,tr,br,bl];
    }

    // === Capture, Perspective Transform, Save ===
    function captureDocument() {
      if (isProcessing) return;
      isProcessing = true;
      let imgData;
      if (lastCorners) {
        imgData = extractDocument(lastCorners);
        showStatus('Document transformed!','success');
      } else {
        hiddenCtx.drawImage(video,0,0,hiddenCanvas.width,hiddenCanvas.height);
        imgData = hiddenCanvas.toDataURL('image/jpeg',0.95);
        showStatus('Full frame captured!','success');
      }
      preview.style.display = 'block';
      previewImg.src = imgData;
      // Optional: Upload/save logic goes here.
      isProcessing = false;
    }
    function extractDocument(corners) {
      const w = Math.max(
        dist(corners[0], corners[1]),
        dist(corners[2], corners[3])
      );
      const h = Math.max(
        dist(corners[0], corners[3]),
        dist(corners[1], corners[2])
      );
      hiddenCtx.drawImage(video,0,0,hiddenCanvas.width,hiddenCanvas.height);
      let src = cv.matFromImageData(hiddenCtx.getImageData(0,0,hiddenCanvas.width,hiddenCanvas.height));
      let dst = new cv.Mat();
      let srcTri = cv.matFromArray(4,1,cv.CV_32FC2, [].concat(...corners));
      let dstTri = cv.matFromArray(4,1,cv.CV_32FC2, [0,0, w,0, w,h, 0,h]);
      let M = cv.getPerspectiveTransform(srcTri, dstTri);
      cv.warpPerspective(src, dst, M, new cv.Size(w,h));
      let outCanvas = document.createElement('canvas');
      outCanvas.width = w; outCanvas.height = h;
      cv.imshow(outCanvas, dst);
      let outURL = outCanvas.toDataURL('image/jpeg',0.95);
      src.delete(); dst.delete(); srcTri.delete(); dstTri.delete(); M.delete();
      return outURL;
    }
    function dist(a,b){ return Math.hypot(a[0]-b[0],a[1]-b[1]); }

    // === Feedback helpers ===
    function showStatus(msg, type='info') {
      statusBox.textContent = msg;
      statusBox.className = 'status ' + (type || '');
      if(type==='success') setTimeout(()=>statusBox.textContent='',2000);
    }

    // === Initialize ===
    cv['onRuntimeInitialized'] = () => {
      startCamera();
    };
    document.addEventListener('visibilitychange', ()=>{
      if(document.hidden && video.srcObject) {
        video.srcObject.getTracks().forEach(t=>t.stop());
      } else if(!document.hidden && !video.srcObject) {
        startCamera();
      }
    });
  </script>
</body>
</html>
